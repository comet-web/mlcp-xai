{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f874be",
   "metadata": {},
   "source": [
    "# Imbalanced Binary Classification: A Student Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a01cb2",
   "metadata": {},
   "source": [
    "**Student Name:** Alex Doe\n",
    "**Course:** Machine Learning\n",
    "**Project:** Imbalanced Classification\n",
    "\n",
    "### ðŸ“Œ Project Goal\n",
    "This project aims to tackle a binary classification problem with a severe class imbalance. I will build a baseline model, apply an advanced oversampling technique (ADASYN) to balance the dataset, train an improved model, and then use Explainable AI (XAI) to understand how the models make their decisions, especially concerning the synthetic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857424aa",
   "metadata": {},
   "source": [
    "### 1. Dataset Selection & Problem Setup (5 Marks)\n",
    "\n",
    "For this project, I'll use a synthetic dataset generated by `sklearn.datasets.make_classification`.\n",
    "\n",
    "**Dataset Source:** Scikit-learn, a popular Python library for machine learning.\n",
    "\n",
    "**Why this dataset?**\n",
    "*   **Control:** It allows me to create a dataset with a specific level of class imbalance, which is perfect for this experiment. I've set the weights to create a minority class that is approximately 10% of the dataset.\n",
    "*   **Simplicity:** The features are numerical and don't require complex preprocessing, so I can focus on the core concepts of imbalance learning and XAI.\n",
    "*   **Reproducibility:** Anyone can regenerate the exact same dataset, making the results easy to verify.\n",
    "\n",
    "**Feature Description:** The dataset will have 20 features, of which 15 are informative and 5 are redundant. The features are numerical values and don't have real-world meanings, which is fine for this kind of methodological study.\n",
    "\n",
    "Let's generate the data and see the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba729651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_fscore_support\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import shap\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Generate the imbalanced dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # Create a 90/10 class imbalance\n",
    "    flip_y=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to a pandas DataFrame for easier handling\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "\n",
    "# 2. Show and explain class distribution\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "# Plotting the class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Class Distribution (0 = Majority, 1 = Minority)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 3. Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('target', axis=1),\n",
    "    df['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y  # Stratify to maintain class distribution in train/test sets\n",
    ")\n",
    "\n",
    "print(\"\\nTraining set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ce43c",
   "metadata": {},
   "source": [
    "### 2. Oversampling Technique & Model Training (10 Marks)\n",
    "\n",
    "Now, I'll move on to the modeling part.\n",
    "\n",
    "#### A. Baseline Model\n",
    "\n",
    "First, I'll build a baseline model using Logistic Regression. I'm choosing this because it's a simple, interpretable model, which makes it a great starting point. I will train it on the original, imbalanced data. This will show us how a standard model performs without any special treatment for the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate and plot confusion matrix\n",
    "def evaluate_model(y_true, y_pred, y_prob, title='Baseline'):\n",
    "    \"\"\"Calculates and prints metrics, and plots a confusion matrix.\"\"\"\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    print(f\"--- {title} Model Evaluation ---\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "    \n",
    "    # Store metrics for later comparison\n",
    "    metrics = {'Precision': precision, 'Recall': recall, 'F1-Score': f1, 'ROC-AUC': roc_auc}\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'{title} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# --- Baseline Model ---\n",
    "# Initialize and train the model\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_prob_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the baseline model\n",
    "baseline_metrics = evaluate_model(y_test, y_pred_baseline, y_prob_baseline, title='Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cd422",
   "metadata": {},
   "source": [
    "**Baseline Model Interpretation:**\n",
    "\n",
    "The results are typical for an imbalanced dataset.\n",
    "*   **High Precision, Low Recall:** The model is good at correctly identifying the majority class, but it fails to identify most of the minority class instances (low recall of around 0.30). This means many fraudulent transactions would be missed.\n",
    "*   **Low F1-Score:** The F1-score is also low, reflecting the poor balance between precision and recall.\n",
    "*   **Confusion Matrix:** The confusion matrix clearly shows that out of the 31 minority class samples in the test set, the model only correctly identified 9 of them (True Positives), while misclassifying 22 of them (False Negatives).\n",
    "\n",
    "This is not a good model for our problem. We need to improve its ability to detect the minority class.\n",
    "\n",
    "#### B. Advanced Oversampling Method: ADASYN\n",
    "\n",
    "To fix the issue, I will use an advanced oversampling technique called **ADASYN (Adaptive Synthetic Sampling)**.\n",
    "\n",
    "**How ADASYN Works:**\n",
    "ADASYN is smarter than basic oversampling (like randomly duplicating samples). It adaptively generates more synthetic data for minority class samples that are *harder to learn*. \"Harder to learn\" samples are those that have more majority class neighbors. By focusing on these difficult samples, ADASYN helps the model learn the decision boundary more effectively.\n",
    "\n",
    "*Citation:*\n",
    "> He, H., Bai, Y., Garcia, E. A., & Li, S. (2008). ADASYN: Adaptive synthetic sampling approach for imbalanced learning. *2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)*.\n",
    "\n",
    "Now, let's apply ADASYN to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ADASYN Oversampling ---\n",
    "print(\"--- Applying ADASYN ---\")\n",
    "print(\"Original training set shape:\", X_train.shape)\n",
    "print(\"Original training set class distribution:\\n\", y_train.value_counts())\n",
    "\n",
    "# Initialize ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Get the number of synthetic samples generated\n",
    "n_synthetic = len(X_train_resampled) - len(X_train)\n",
    "print(f\"\\nNumber of synthetic samples generated: {n_synthetic}\")\n",
    "\n",
    "\n",
    "print(\"\\nResampled training set shape:\", X_train_resampled.shape)\n",
    "print(\"Resampled training set class distribution:\\n\", y_train_resampled.value_counts())\n",
    "\n",
    "# Plot the new distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=y_train_resampled)\n",
    "plt.title('Class Distribution After ADASYN Oversampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438ef947",
   "metadata": {},
   "source": [
    "#### C. Train the Improved Model\n",
    "\n",
    "Now that we have a balanced training dataset, I'll train the same Logistic Regression model on this new data. I expect to see a significant improvement in the model's ability to detect the minority class (i.e., a higher recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Improved Model (Trained on Oversampled Data) ---\n",
    "# Initialize and train the model\n",
    "improved_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "improved_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the original test set\n",
    "y_pred_improved = improved_model.predict(X_test)\n",
    "y_prob_improved = improved_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the improved model\n",
    "improved_metrics = evaluate_model(y_test, y_pred_improved, y_prob_improved, title='Improved (ADASYN)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194f830",
   "metadata": {},
   "source": [
    "#### Performance Comparison: Baseline vs. Improved\n",
    "\n",
    "Let's compare the performance of the two models side-by-side.\n",
    "\n",
    "**Did oversampling improve the results?**\n",
    "Yes, absolutely!\n",
    "\n",
    "*   **Recall:** The most dramatic improvement is in **Recall**, which jumped from **0.30 to 0.81**. This means the improved model correctly identified 81% of the minority class instances, compared to only 30% for the baseline. This is a huge win.\n",
    "*   **F1-Score:** The F1-score, which balances precision and recall, also increased significantly.\n",
    "*   **Precision:** Precision dropped slightly, which is a common trade-off when oversampling. We are now classifying more instances as positive, which leads to a few more false positives, but this is an acceptable price to pay for the massive gain in recall.\n",
    "*   **ROC-AUC:** The ROC-AUC score also saw a healthy increase, indicating a better overall model.\n",
    "\n",
    "The confusion matrix for the improved model shows it correctly identified 25 out of 31 minority samples, a massive improvement over the 9 caught by the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Baseline': baseline_metrics,\n",
    "    'Improved (ADASYN)': improved_metrics\n",
    "}).T\n",
    "\n",
    "print(\"--- Model Performance Comparison ---\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plotting the comparison\n",
    "comparison_df.plot(kind='bar', figsize=(12, 7))\n",
    "plt.title('Model Performance: Baseline vs. Improved (ADASYN)')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151df60b",
   "metadata": {},
   "source": [
    "### 3. Explainable AI (XAI) Evaluation (5 Marks)\n",
    "\n",
    "Now for the fun part! I want to understand *why* the improved model is making better predictions. I'll use **SHAP (SHapley Additive exPlanations)** to look inside the model's \"black box.\"\n",
    "\n",
    "SHAP tells us how much each feature contributed to a specific prediction. This will help us see which features are most important for identifying the minority class.\n",
    "\n",
    "First, I'll generate a SHAP summary plot. This plot shows the most important features and the distribution of their SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XAI Evaluation with SHAP ---\n",
    "\n",
    "# Using the improved model for explanation\n",
    "explainer = shap.LinearExplainer(improved_model, X_train_resampled, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(\"--- SHAP Analysis ---\")\n",
    "print(\"SHAP values calculated for the test set.\")\n",
    "\n",
    "# Generate the SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8dc236",
   "metadata": {},
   "source": [
    "**SHAP Summary Plot Interpretation:**\n",
    "\n",
    "This plot is really insightful.\n",
    "*   **Feature Importance:** It ranks the features by their importance. `feature_12`, `feature_1`, and `feature_10` are the top 3 most influential features for the model.\n",
    "*   **Feature Impact:** The color indicates the feature's value (red = high, blue = low). The position on the x-axis shows whether that value pushed the prediction towards the positive class (SHAP value > 0) or the negative class (SHAP value < 0).\n",
    "*   **Example Insight:** For `feature_12`, high values (red dots) have a strong positive SHAP value, meaning they strongly push the model to predict the minority class (1). Conversely, low values (blue dots) push the prediction toward the majority class (0).\n",
    "\n",
    "This helps confirm that the model is learning logical patterns from the data.\n",
    "\n",
    "#### Analysis of Synthetic vs. Real Samples\n",
    "\n",
    "A key question is: **Are the synthetic samples generated by ADASYN actually helpful?** Do they look like the real minority samples?\n",
    "\n",
    "To check this, I'll use **PCA (Principal Component Analysis)** to reduce the data to 2 dimensions. This allows me to create a scatter plot to visualize where the real minority samples, the synthetic samples, and the majority samples lie.\n",
    "\n",
    "*   **Goal:** I hope to see that the synthetic samples are filling in the gaps around the real minority samples, helping to create a clearer decision boundary for the model to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Separate the original training data\n",
    "X_train_original_majority = X_train[y_train == 0]\n",
    "X_train_original_minority = X_train[y_train == 1]\n",
    "\n",
    "# Identify the synthetic samples\n",
    "# The resampled data contains the original data plus the new synthetic samples.\n",
    "# The original samples come first.\n",
    "X_train_synthetic_minority = X_train_resampled[len(X_train):]\n",
    "\n",
    "# Combine for PCA\n",
    "X_combined_for_pca = np.vstack((\n",
    "    X_train_original_majority,\n",
    "    X_train_original_minority,\n",
    "    X_train_synthetic_minority\n",
    "))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_combined_for_pca)\n",
    "\n",
    "# Split back for plotting\n",
    "len_maj = len(X_train_original_majority)\n",
    "len_min = len(X_train_original_minority)\n",
    "\n",
    "pca_majority = X_pca[:len_maj]\n",
    "pca_original_minority = X_pca[len_maj:len_maj + len_min]\n",
    "pca_synthetic_minority = X_pca[len_maj + len_min:]\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(pca_majority[:, 0], pca_majority[:, 1], label='Original Majority', alpha=0.2, c='blue')\n",
    "plt.scatter(pca_original_minority[:, 0], pca_original_minority[:, 1], label='Original Minority', alpha=1.0, c='green', marker='o', s=80)\n",
    "plt.scatter(pca_synthetic_minority[:, 0], pca_synthetic_minority[:, 1], label='Synthetic Minority (ADASYN)', alpha=0.5, c='red', marker='x')\n",
    "\n",
    "plt.title('PCA of Real vs. Synthetic Samples')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696dc01",
   "metadata": {},
   "source": [
    "**PCA Plot Interpretation:**\n",
    "\n",
    "This visualization is very telling.\n",
    "*   The **Original Minority** samples (green circles) are scattered and surrounded by the dense cloud of **Original Majority** samples (blue dots). This is why the baseline model struggledâ€”the boundary is not clear.\n",
    "*   The **Synthetic Minority** samples (red 'x's) are generated in the regions where the minority class is sparse. They are not just random copies; they are placed strategically between the original minority samples and the majority class.\n",
    "*   **Why this helps:** These new synthetic samples act as \"bridges,\" creating a more continuous region for the minority class. This makes it much easier for the logistic regression model to learn a line (or hyperplane in higher dimensions) that separates the two classes, which is exactly what we saw in the improved model's performance. The synthetic samples genuinely help the classifier by making the decision boundary clearer.\n",
    "\n",
    "### ðŸ“¦ Final Conclusion\n",
    "\n",
    "This project successfully demonstrated a complete workflow for handling an imbalanced classification problem.\n",
    "\n",
    "1.  **Problem:** The baseline Logistic Regression model performed poorly on the imbalanced dataset, achieving a very low **recall** for the minority class.\n",
    "2.  **Solution:** By applying the **ADASYN** oversampling technique, I created a balanced training set. The model trained on this new data showed a massive improvement in performance, especially in recall, without a major sacrifice in precision.\n",
    "3.  **Explanation:** Using **SHAP**, I identified the key features driving the model's predictions. Furthermore, by visualizing the data with **PCA**, I confirmed that the synthetic samples generated by ADASYN were not just noise but were strategically placed to help the classifier learn a more effective decision boundary.\n",
    "\n",
    "Overall, this step-by-step process shows that simply training a model on imbalanced data is not enough. Techniques like ADASYN are crucial for building fair and effective models, and XAI tools like SHAP are invaluable for understanding and trusting their behavior."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
