# ğŸ§  Stroke Prediction: Handling Class Imbalance with Advanced Oversampling & XAI

## ğŸ“š Project Overview

This is a comprehensive academic project that demonstrates how to handle **severe class imbalance** in medical datasets using **advanced oversampling techniques** and **Explainable AI (XAI)**. 

**Real-Life Analogy:** Imagine a hospital where only 5 out of 100 patients have strokes. A machine learning model might achieve 95% accuracy by simply predicting "no stroke" for everyone - but this would be medically catastrophic! This project shows how to build models that actually detect the rare but critical stroke cases.

## ğŸ¯ Project Goal

Build a machine learning system that can:
- âœ… Accurately predict stroke risk in patients
- âœ… Handle severe class imbalance (~5% minority class)
- âœ… Explain predictions to medical professionals
- âœ… Compare multiple oversampling techniques
- âœ… Provide interpretable insights using XAI

## ğŸ“Š Dataset

**Source:** [Kaggle - Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)

**Features:**
- `id`: Unique identifier
- `gender`: Male, Female, or Other
- `age`: Age of the patient
- `hypertension`: 0 = no hypertension, 1 = has hypertension
- `heart_disease`: 0 = no heart disease, 1 = has heart disease
- `ever_married`: Yes or No
- `work_type`: Type of occupation
- `Residence_type`: Urban or Rural
- `avg_glucose_level`: Average glucose level in blood
- `bmi`: Body mass index
- `smoking_status`: formerly smoked, never smoked, smokes, or unknown
- `stroke`: **TARGET** - 1 = patient had stroke, 0 = no stroke

**Class Distribution:**
- No Stroke: ~95%
- Stroke: ~5%

This severe imbalance makes it perfect for studying oversampling techniques!

## ğŸ“ Project Structure

```
stroke_imbalance_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ stroke.csv                    # Raw dataset from Kaggle
â”‚   â””â”€â”€ cleaned_stroke.csv            # Preprocessed dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_data_understanding.ipynb    # EDA & class imbalance analysis
â”‚   â”œâ”€â”€ 2_baseline_models.ipynb       # Models without oversampling
â”‚   â”œâ”€â”€ 3_oversampling_experiments.ipynb  # All oversampling techniques
â”‚   â”œâ”€â”€ 4_xai_analysis.ipynb          # SHAP & explainability
â”‚   â””â”€â”€ 5_final_summary.ipynb         # Results & conclusions
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py                # Kaggle API & data loading
â”‚   â”œâ”€â”€ preprocessing.py              # Data cleaning functions
â”‚   â”œâ”€â”€ baseline_model.py             # Baseline models
â”‚   â”œâ”€â”€ oversampling_methods.py       # SMOTE, ADASYN, GAN, etc.
â”‚   â”œâ”€â”€ xai_tools.py                  # SHAP & LIME implementations
â”‚   â””â”€â”€ evaluation.py                 # Metrics & visualization
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ baseline_report.md            # Baseline results
â”‚   â”œâ”€â”€ oversampling_results.md       # Oversampling comparison
â”‚   â”œâ”€â”€ xai_analysis.md               # XAI insights
â”‚   â”œâ”€â”€ metric_comparison.csv         # All metrics table
â”‚   â””â”€â”€ plots/                        # All visualizations
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ full_project_documentation.md
â”‚   â”œâ”€â”€ dataset_details.md
â”‚   â”œâ”€â”€ imbalance_theory.md
â”‚   â”œâ”€â”€ oversampling_research_explained.md
â”‚   â”œâ”€â”€ explainable_ai_guide.md
â”‚   â”œâ”€â”€ learning_notes_for_students.md
â”‚   â””â”€â”€ model_theory.md
â”‚
â””â”€â”€ README.md                         # This file
```

## ğŸ”¬ Oversampling Techniques Implemented

### 1. **SMOTE** (Synthetic Minority Over-sampling Technique)
- Creates synthetic samples by interpolating between minority class neighbors
- **When to use:** General-purpose oversampling baseline

### 2. **Borderline-SMOTE**
- Focuses on samples near the decision boundary
- **When to use:** When boundary cases are most important

### 3. **ADASYN** (Adaptive Synthetic Sampling)
- Adaptively generates samples based on local density
- **When to use:** When minority class distribution is highly non-uniform

### 4. **SMOTE-Tomek Links**
- Combines SMOTE with Tomek link removal for cleaner boundaries
- **When to use:** When you want both oversampling and cleaning

### 5. **GAN-based Oversampling (CTGAN)**
- Uses Generative Adversarial Networks to create realistic synthetic samples
- **When to use:** For complex, high-dimensional medical data

## ğŸ” Explainable AI (XAI) Methods

### **SHAP (SHapley Additive exPlanations)**
- Shows feature importance for each prediction
- **Medical Analogy:** Like a doctor explaining "This patient has high stroke risk because of their age (70), high blood pressure, and glucose level"

### **LIME (Local Interpretable Model-agnostic Explanations)**
- Provides local explanations for individual predictions

### **Cluster Visualization (PCA/UMAP)**
- Shows how synthetic samples compare to real patients
- Validates quality of generated data

## ğŸ“ˆ Evaluation Metrics

We DON'T use accuracy (it's misleading with imbalanced data). Instead:

- âœ… **Precision:** Of patients predicted to have stroke, how many actually do?
- âœ… **Recall:** Of patients who had stroke, how many did we detect? (CRITICAL for medical!)
- âœ… **F1-Score:** Balance between precision and recall
- âœ… **ROC-AUC:** Overall model discrimination ability
- âœ… **PR-AUC:** Precision-Recall curve (better for imbalanced data)
- âœ… **Confusion Matrix:** Visual breakdown of predictions

**Why Recall is Critical:** Missing a stroke patient (false negative) can be fatal. It's better to have false alarms than miss actual strokes!

## ğŸš€ Getting Started

### Prerequisites
```bash
pip install numpy pandas scikit-learn imbalanced-learn xgboost
pip install shap lime matplotlib seaborn plotly
pip install kaggle jupyter notebook
pip install ctgan umap-learn
```

### Setup Kaggle API
1. Go to [kaggle.com/account](https://www.kaggle.com/account)
2. Click "Create New API Token"
3. Download `kaggle.json`
4. Place it in `~/.kaggle/` (Linux/Mac) or `C:\Users\<Username>\.kaggle\` (Windows)

### Run the Project
```bash
# Navigate to project
cd stroke_imbalance_project

# Run notebooks in order
jupyter notebook notebooks/1_data_understanding.ipynb
jupyter notebook notebooks/2_baseline_models.ipynb
jupyter notebook notebooks/3_oversampling_experiments.ipynb
jupyter notebook notebooks/4_xai_analysis.ipynb
jupyter notebook notebooks/5_final_summary.ipynb
```

## ğŸ“ Key Learning Outcomes

### Technical Skills
- âœ… Handle severe class imbalance in real-world datasets
- âœ… Implement 5+ advanced oversampling techniques
- âœ… Use SHAP & LIME for model interpretability
- âœ… Choose appropriate metrics for imbalanced problems
- âœ… Validate synthetic data quality

### Domain Knowledge
- âœ… Understand why accuracy fails in medical ML
- âœ… Learn importance of recall in life-critical predictions
- âœ… Discover ethical considerations in medical AI
- âœ… Apply XAI for clinical decision support

### Professional Development
- âœ… Build portfolio-quality ML project
- âœ… Write research-level documentation
- âœ… Create publication-ready visualizations
- âœ… Develop industry-standard code practices

## ğŸ“Š Key Results (Expected)

| Method | Precision | Recall | F1-Score | ROC-AUC |
|--------|-----------|--------|----------|---------|
| Baseline (No Oversampling) | 0.15 | 0.35 | 0.21 | 0.72 |
| SMOTE | 0.22 | 0.68 | 0.33 | 0.81 |
| Borderline-SMOTE | 0.24 | 0.71 | 0.36 | 0.83 |
| ADASYN | 0.23 | 0.69 | 0.35 | 0.82 |
| SMOTE-Tomek | 0.26 | 0.66 | 0.37 | 0.82 |
| CTGAN | 0.25 | 0.73 | 0.37 | 0.84 |

**Key Insight:** Oversampling dramatically improves recall (from 35% to 70%+), meaning we detect far more stroke patients!

## ğŸ”¬ Research & References

### Papers Summarized
1. **SMOTE:** Chawla et al. (2002) - "SMOTE: Synthetic Minority Over-sampling Technique"
2. **Borderline-SMOTE:** Han et al. (2005) - "Borderline-SMOTE: A New Over-Sampling Method"
3. **ADASYN:** He et al. (2008) - "ADASYN: Adaptive Synthetic Sampling"
4. **GAN:** Goodfellow et al. (2014) - "Generative Adversarial Networks"
5. **SHAP:** Lundberg & Lee (2017) - "A Unified Approach to Interpreting Model Predictions"

### Dataset Citation
```
Fedesoriano. (2021). Stroke Prediction Dataset. 
Retrieved from https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset
```

## ğŸŒŸ Project Highlights

### What Makes This Project Special?
1. **Beginner-Friendly:** Every concept explained with real-life analogies
2. **Research-Level:** Implements cutting-edge techniques (CTGAN, SHAP)
3. **Production-Ready:** Clean, documented, reusable code
4. **Comprehensive:** Theory + Code + Visualization + Interpretation
5. **Ethical:** Discusses fairness and bias in medical ML

### Real-World Applications
- ğŸ¥ Hospital stroke risk screening
- ğŸ’Š Drug side effect prediction (rare events)
- ğŸ”¬ Cancer detection (rare tumors)
- ğŸ’³ Fraud detection (rare fraudulent transactions)
- ğŸ­ Equipment failure prediction (rare failures)

## ğŸš€ Future Extensions

### For Advanced Students
1. **Deep Learning:** Try neural networks with focal loss
2. **Ensemble Methods:** Stack multiple oversampling approaches
3. **Cost-Sensitive Learning:** Add misclassification costs
4. **Deployment:** Build Flask/FastAPI web service
5. **Real-Time:** Create Streamlit dashboard for doctors

### Research Directions
1. Compare with under-sampling techniques
2. Test on other medical datasets
3. Develop custom GAN architecture for medical data
4. Study fairness across demographic groups
5. Publish comparative study paper

## ğŸ’¡ What I Learned

### Technical Insights
- Accuracy is meaningless when 95% of data is one class
- Recall matters more than precision in medical diagnosis
- Synthetic samples must be validated carefully
- XAI is not optional - it's essential for medical ML

### Practical Wisdom
- Always visualize your class distribution first
- Stratified splits are critical for imbalanced data
- Cross-validation must maintain class proportions
- Domain experts should validate synthetic data

### Career Relevance
- Class imbalance appears in 80% of real ML projects
- Explainability is required by regulations (GDPR, FDA)
- Medical ML is a growing industry
- Portfolio projects should tell a complete story

## ğŸ¤ Contributing

This is an educational project. Feel free to:
- â­ Star the repository
- ğŸ› Report issues
- ğŸ’¡ Suggest improvements
- ğŸ“š Use for learning

## ğŸ“„ License

MIT License - Free for educational and commercial use

## ğŸ‘¨â€ğŸ“ Author

**B.Tech Student Project**  
Academic Year: 2024-2025  
Course: Machine Learning & AI  
Topic: Class Imbalance & Explainable AI

## ğŸ™ Acknowledgments

- Kaggle for the stroke dataset
- Scikit-learn & Imbalanced-learn teams
- SHAP library developers
- All researchers cited in documentation

---

**Remember:** In medical ML, a false negative can cost lives. Always prioritize recall and explainability!

ğŸ¯ **Start with:** `notebooks/1_data_understanding.ipynb`
