{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install requirements in notebook runtime (uncomment if needed)\n",
    "# !pip install -q -r ../requirements.txt\n",
    "import os, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from src import config\n",
    "from src.utils import ensure_dirs, set_global_seed, save_json\n",
    "from src.data_loader import download_stroke_dataset\n",
    "from src.preprocess import get_feature_types, build_preprocessor, fit_transform, transform, ctgan_prepare_training_df\n",
    "from src.models import train_and_eval\n",
    "from src.oversampling import apply_smote, train_ctgan_and_generate\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "ensure_dirs()\n",
    "set_global_seed(config.SEED)\n",
    "print('Directories ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load dataset using Kaggle API\n",
    "csv_path = download_stroke_dataset(config.RAW_DIR)\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: summary, types, missing, class distribution, save to artifacts\n",
    "summary = {\n",
    "    'shape': df.shape,\n",
    "    'dtypes': {c: str(t) for c, t in df.dtypes.items()},\n",
    "    'missing': df.isna().sum().to_dict(),\n",
    "}\n",
    "target = config.TARGET_COL\n",
    "cls_counts = df[target].value_counts().to_dict()\n",
    "cls_pct = (df[target].value_counts(normalize=True)\n",
    "            .rename(lambda x: f'class_{x}')\n",
    "            .mul(100).round(2).to_dict())\n",
    "summary['class_counts'] = cls_counts\n",
    "summary['class_percentages'] = cls_pct\n",
    "print('Class distribution (%):', cls_pct)\n",
    "save_json(summary, os.path.join(config.ARTIFACTS_DIR, 'data_summary.json'))\n",
    "pd.Series(cls_counts).plot(kind='bar', title='Class Counts'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f9399",
   "metadata": {},
   "source": [
    "## Train/Test Split and Preprocessing\n",
    "- Stratified split with held-out test set.\n",
    "- Tree models do not require scaling; we use OneHot for categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489094dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "y = df[target].values\n",
    "X = df.drop(columns=[target])\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=config.TEST_SIZE, stratify=y, random_state=config.SEED\n",
    ")\n",
    "# Preprocessing\n",
    "num_cols, cat_cols = get_feature_types(df)\n",
    "pre = build_preprocessor(num_cols, cat_cols)\n",
    "X_train, feat_names = fit_transform(pre, X_train_raw)\n",
    "X_test = transform(pre, X_test_raw)\n",
    "X_train = X_train.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train.shape, X_test.shape, len(feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6b033",
   "metadata": {},
   "source": [
    "## Baseline: XGBoost (no resampling)\n",
    "- Also compute class-weighted baseline via scale_pos_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e574c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weight ratio for reference\n",
    "n_min = int((y_train == 1).sum()); n_maj = int((y_train == 0).sum())\n",
    "spw = n_maj / max(1, n_min)\n",
    "print('scale_pos_weight:', round(spw, 2))\n",
    "\n",
    "cv_base, test_base, model_base = train_and_eval(X_train, y_train, X_test, y_test, scale_pos_weight=None)\n",
    "cv_weighted, test_weighted, model_weighted = train_and_eval(X_train, y_train, X_test, y_test, scale_pos_weight=spw)\n",
    "print('Baseline test ROC AUC:', round(test_base['roc_auc'], 4))\n",
    "print('Weighted test ROC AUC:', round(test_weighted['roc_auc'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24dfcf6",
   "metadata": {},
   "source": [
    "## SMOTE Oversampling (train folds only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = apply_smote(X_train, y_train, target_ratio=config.SMOTE_TARGET_RATIO)\n",
    "cv_smote, test_smote, model_smote = train_and_eval(X_smote, y_smote, X_test, y_test)\n",
    "print('SMOTE test ROC AUC:', round(test_smote['roc_auc'], 4))\n",
    "# Save SMOTE synthetic indices (minority ones) is non-trivial post-resampling; skip detailed extraction.\n",
    "# Instead, log counts\n",
    "smote_info = {'train_size': int(len(y_train)), 'resampled_size': int(len(y_smote)), 'target_ratio': config.SMOTE_TARGET_RATIO}\n",
    "save_json(smote_info, os.path.join(config.ARTIFACTS_DIR, 'smote_info.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225f387",
   "metadata": {},
   "source": [
    "## CTGAN Oversampling (conditional minority generation)\n",
    "- Train CTGAN on training data (with discrete columns), generate minority rows to reach target ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare CTGAN training DF with imputations and discrete columns\n",
    "train_df_ctgan = X_train_raw.copy()\n",
    "train_df_ctgan[target] = y_train\n",
    "train_df_ctgan, discrete_cols = ctgan_prepare_training_df(train_df_ctgan)\n",
    "print('CTGAN discrete columns:', discrete_cols)\n",
    "\n",
    "synth_min = train_ctgan_and_generate(train_df_ctgan, discrete_columns=discrete_cols, target_col=target, target_ratio=config.CTGAN_TARGET_RATIO, save_dir=config.CTGAN_DIR)\n",
    "print('Generated minority rows:', len(synth_min))\n",
    "# Save synthetic CSV\n",
    "ctgan_csv = os.path.join(config.ARTIFACTS_DIR, 'synthetic_ctgan_minority.csv')\n",
    "synth_min.to_csv(ctgan_csv, index=False)\n",
    "\n",
    "# Encode synthetic to training feature space\n",
    "if len(synth_min) > 0:\n",
    "    X_synth_enc = transform(pre, synth_min.drop(columns=[target]))\n",
    "    y_synth = synth_min[target].values.astype(int)\n",
    "    X_ctgan = np.vstack([X_train, X_synth_enc]).astype('float32')\n",
    "    y_ctgan = np.concatenate([y_train, y_synth])\n",
    "else:\n",
    "    X_ctgan, y_ctgan = X_train, y_train\n",
    "\n",
    "cv_ctgan, test_ctgan, model_ctgan = train_and_eval(X_ctgan, y_ctgan, X_test, y_test)\n",
    "print('CTGAN test ROC AUC:', round(test_ctgan['roc_auc'], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c3965",
   "metadata": {},
   "source": [
    "## Compare Metrics and Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b55bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score\n",
    "\n",
    "comparison = {\n",
    "    'baseline': test_base,\n",
    "    'weighted': test_weighted,\n",
    "    'smote': test_smote,\n",
    "    'ctgan': test_ctgan,\n",
    "}\n",
    "save_json(comparison, os.path.join(config.ARTIFACTS_DIR, 'metrics.json'))\n",
    "pd.DataFrame(comparison).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC/PR curves for the three models on the same axes\n",
    "def collect_curves(model, X, y):\n",
    "    prob = model.predict_proba(X)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y, prob)\n",
    "    prec, rec, _ = precision_recall_curve(y, prob)\n",
    "    ap = average_precision_score(y, prob)\n",
    "    return (fpr, tpr), (rec, prec), ap\n",
    "\n",
    "curves = {\n",
    "    'baseline': collect_curves(model_base, X_test, y_test),\n",
    "    'smote': collect_curves(model_smote, X_test, y_test),\n",
    "    'ctgan': collect_curves(model_ctgan, X_test, y_test),\n",
    "}\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "for k,(roc_c, pr_c, ap) in curves.items():\n",
    "    fpr,tpr = roc_c; rec,prec = pr_c\n",
    "    axes[0].plot(fpr,tpr,label=k)\n",
    "    axes[1].plot(rec,prec,label=f\n",
    ")\n",
    "axes[0].plot([0,1],[0,1],'k--',alpha=.3); axes[0].set_title('ROC')\n",
    "axes[0].set_xlabel('FPR'); axes[0].set_ylabel('TPR')\n",
    "axes[1].set_title('Precision-Recall'); axes[1].set_xlabel('Recall'); axes[1].set_ylabel('Precision')\n",
    "axes[0].legend(); axes[1].legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34474075",
   "metadata": {},
   "source": [
    "## Calibration & Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "def plot_thresholds(model, X, y):\n",
    "    prob = model.predict_proba(X)[:,1]\n",
    "    prec, rec, th = precision_recall_curve(y, prob)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "    ax[0].plot(rec, prec); ax[0].set_title('PR Curve'); ax[0].set_xlabel('Recall'); ax[0].set_ylabel('Precision')\n",
    "    ax[1].plot(th, prec[:-1], label='Precision'); ax[1].plot(th, rec[:-1], label='Recall');\n",
    "    ax[1].legend(); ax[1].set_title('Threshold vs Precision/Recall'); ax[1].set_xlabel('Threshold')\n",
    "    plt.show()\n",
    "\n",
    "plot_thresholds(model_ctgan, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703828c",
   "metadata": {},
   "source": [
    "## Conclusion (fill after running)\n",
    "- Did CTGAN improve minority recall vs baseline and SMOTE?\n",
    "- Numeric changes: recall_class1 and PR AUC deltas.\n",
    "- Trade-offs in precision and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models to models/\n",
    "import joblib, os\n",
    "from src import config\n",
    "\n",
    "os.makedirs(config.MODELS_DIR, exist_ok=True)\n",
    "joblib.dump(model_base, os.path.join(config.MODELS_DIR, 'baseline_model.pkl'))\n",
    "joblib.dump(model_smote, os.path.join(config.MODELS_DIR, 'smote_model.pkl'))\n",
    "joblib.dump(model_ctgan, os.path.join(config.MODELS_DIR, 'ctgan_model.pkl'))\n",
    "print('Saved models to', config.MODELS_DIR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
