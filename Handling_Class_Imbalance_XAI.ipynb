{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a2d059",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance with Oversampling & Explainable AI\n",
    "\n",
    "**Short abstract:** This notebook explores the challenge of class imbalance in machine learning using the Stroke Prediction Dataset. We will demonstrate how advanced oversampling techniques, specifically SMOTE (Synthetic Minority Over-sampling Technique), can improve model performance for predicting the minority class (stroke patients). We then use Explainable AI (XAI) with SHAP to understand the model's decisions and analyze the characteristics of the synthetic data. The main takeaway is that oversampling can significantly boost recall for the minority class, and XAI helps verify that the model learns meaningful patterns from the synthetic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcb1ed",
   "metadata": {},
   "source": [
    "## Problem Framing & Real-world Motivation\n",
    "\n",
    "Class imbalance is a common problem in machine learning where the number of examples for one class is vastly different from another. In our case, we're looking at medical data for stroke prediction.\n",
    "\n",
    "Imagine a dataset of 1000 patients where only 20 have had a stroke. A simple model could achieve 98% accuracy by just predicting \"no stroke\" for everyone. While accurate, this model is useless because it fails to identify the patients who actually had a stroke, which is the entire point of the prediction!\n",
    "\n",
    "Missing a stroke prediction (a \"false negative\") is far more costly than incorrectly flagging a healthy patient for a follow-up (a \"false positive\"). This is why we need techniques to handle class imbalance and build models that are good at finding the rare, important cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d1d55",
   "metadata": {},
   "source": [
    "## Dataset Selection & Quick EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc5027",
   "metadata": {},
   "source": [
    "We will use the \"Stroke Prediction Dataset\" from Kaggle. It's a good choice because it's small, tabular, and has a clear class imbalance, making it perfect for this student project.\n",
    "\n",
    "**Dataset Options:**\n",
    "*   **Option 1 (Chosen):** Kaggle Stroke Prediction Dataset (small, ~5000 rows)\n",
    "*   **Option 2:** Kaggle Credit Card Fraud Detection (larger, ~280,000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b27cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and random seed set.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make sure the figures directory exists\n",
    "if not os.path.exists('figures'):\n",
    "    os.makedirs('figures')\n",
    "\n",
    "print(\"Libraries imported and random seed set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981f8ab",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "The dataset is expected to be in the same folder as this notebook.\n",
    "Dataset Source: [Kaggle Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53abe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset shape: (5110, 12)\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset from the CSV file\n",
    "try:\n",
    "    df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'healthcare-dataset-stroke-data.csv' not found. Please place it in the same folder as the notebook.\")\n",
    "\n",
    "# Display dataset shape\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40025393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "stroke\n",
      "0    4861\n",
      "1     249\n",
      "Name: count, dtype: int64\n",
      "\n",
      "No Stroke: 95.13%\n",
      "Stroke: 4.87%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n",
      "None\n",
      "\n",
      "Missing Value Summary:\n",
      "id                     0\n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "Residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  201\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Class Distribution:\")\n",
    "class_dist = df['stroke'].value_counts()\n",
    "class_dist_percent = df['stroke'].value_counts(normalize=True) * 100\n",
    "print(class_dist)\n",
    "print(f\"\\nNo Stroke: {class_dist_percent[0]:.2f}%\")\n",
    "print(f\"Stroke: {class_dist_percent[1]:.2f}%\")\n",
    "\n",
    "# Plot the class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='stroke', data=df)\n",
    "plt.title('Class Distribution (0 = No Stroke, 1 = Stroke)')\n",
    "plt.savefig('figures/class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Display feature types\n",
    "print(\"\\nFeature Types:\")\n",
    "print(df.info())\n",
    "\n",
    "# Missing value summary\n",
    "print(\"\\nMissing Value Summary:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45104433",
   "metadata": {},
   "source": [
    "**Justification for Dataset Choice:**\n",
    "\n",
    "This dataset is ideal for our project because:\n",
    "*   It has a significant class imbalance (only ~5% of samples are in the minority 'stroke' class).\n",
    "*   It's a manageable size, allowing for quick model training and experimentation on a standard laptop.\n",
    "*   It contains a mix of numerical and categorical features, which is common in real-world data and requires a preprocessing pipeline.\n",
    "\n",
    "---\n",
    "***Mini-Reflection:*** *I was surprised to see how few stroke cases are in the dataset. It really highlights why accuracy isn't a good metric. A model could ignore all the stroke patients and still be 95% accurate! This makes me realize how important it is to look at other metrics like recall.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43081f",
   "metadata": {},
   "source": [
    "## Baseline Modeling (No Oversampling)\n",
    "\n",
    "Now, let's build a couple of models on the original, imbalanced data. This will be our baseline to see if oversampling actually helps. We'll create a preprocessing pipeline to handle missing values and categorical features, then train a simple Logistic Regression and a more powerful Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2683472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "Numerical features: ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.051434</td>\n",
       "      <td>-0.328602</td>\n",
       "      <td>4.185032</td>\n",
       "      <td>2.706375</td>\n",
       "      <td>1.001234e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786070</td>\n",
       "      <td>-0.328602</td>\n",
       "      <td>-0.238947</td>\n",
       "      <td>2.121559</td>\n",
       "      <td>4.615554e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.626390</td>\n",
       "      <td>-0.328602</td>\n",
       "      <td>4.185032</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>4.685773e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255342</td>\n",
       "      <td>-0.328602</td>\n",
       "      <td>-0.238947</td>\n",
       "      <td>1.437358</td>\n",
       "      <td>7.154182e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.582163</td>\n",
       "      <td>3.043196</td>\n",
       "      <td>-0.238947</td>\n",
       "      <td>1.501184</td>\n",
       "      <td>-6.357112e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3             4    5    6    7    8   \\\n",
       "0  1.051434 -0.328602  4.185032  2.706375  1.001234e+00  0.0  1.0  0.0  1.0   \n",
       "1  0.786070 -0.328602 -0.238947  2.121559  4.615554e-16  1.0  0.0  0.0  1.0   \n",
       "2  1.626390 -0.328602  4.185032 -0.005028  4.685773e-01  0.0  1.0  0.0  1.0   \n",
       "3  0.255342 -0.328602 -0.238947  1.437358  7.154182e-01  1.0  0.0  0.0  1.0   \n",
       "4  1.582163  3.043196 -0.238947  1.501184 -6.357112e-01  1.0  0.0  0.0  1.0   \n",
       "\n",
       "    9    10   11   12   13   14   15   16   17   18   19  \n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "4  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "\n",
    "# Drop the 'id' column as it's not a useful feature\n",
    "df = df.drop('id', axis=1)\n",
    "\n",
    "# Handle the 'Other' gender category - only one sample, so we'll replace it with the mode\n",
    "gender_mode = df['gender'].mode()[0]\n",
    "df['gender'] = df['gender'].replace('Other', gender_mode)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(include=np.number).columns\n",
    "\n",
    "print(\"Categorical features:\", list(categorical_features))\n",
    "print(\"Numerical features:\", list(numerical_features))\n",
    "\n",
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "# For numerical features, we'll impute missing values (for BMI) with the mean and then scale them.\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For categorical features, we'll one-hot encode them.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a preprocessor object using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Let's see how the preprocessor transforms the data\n",
    "# This is a good check to make sure everything is working as expected\n",
    "pd.DataFrame(preprocessor.fit_transform(X)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89839df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4088, 10)\n",
      "Test set shape: (1022, 10)\n",
      "\n",
      "Training set class distribution:\n",
      "stroke\n",
      "0    0.951321\n",
      "1    0.048679\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "stroke\n",
      "0    0.951076\n",
      "1    0.048924\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the stratified train/test split\n",
    "# We use stratify=y to ensure that the proportion of stroke vs. no-stroke is the same in both the train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bfc46",
   "metadata": {},
   "source": [
    "### Train and Evaluate Baseline Models\n",
    "\n",
    "We'll define a function to train and evaluate our models to keep the code clean and reusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712ba8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "\n",
      "Training Random Forest model...\n",
      "\n",
      "--- Evaluation on Test Set ---\n",
      "--- Logistic Regression Performance ---\n",
      "Accuracy: 0.7456\n",
      "ROC-AUC: 0.8439\n",
      "PR-AUC: 0.2677\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.99      0.74      0.85       972\n",
      "      Stroke       0.14      0.80      0.24        50\n",
      "\n",
      "    accuracy                           0.75      1022\n",
      "   macro avg       0.56      0.77      0.54      1022\n",
      "weighted avg       0.94      0.75      0.82      1022\n",
      "\n",
      "\n",
      "--- Evaluation on Test Set ---\n",
      "--- Logistic Regression Performance ---\n",
      "Accuracy: 0.7456\n",
      "ROC-AUC: 0.8439\n",
      "PR-AUC: 0.2677\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.99      0.74      0.85       972\n",
      "      Stroke       0.14      0.80      0.24        50\n",
      "\n",
      "    accuracy                           0.75      1022\n",
      "   macro avg       0.56      0.77      0.54      1022\n",
      "weighted avg       0.94      0.75      0.82      1022\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'metrics' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Evaluation on Test Set ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Evaluate the models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m baseline_metrics_lr, y_proba_lr = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLogistic Regression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m baseline_metrics_rf, y_proba_rf = evaluate_model(rand_forest, X_test, y_test, \u001b[33m\"\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Store results in a DataFrame\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, X_test, y_test, model_name)\u001b[39m\n\u001b[32m     32\u001b[39m plt.show()\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Return a dictionary of metrics for later comparison\u001b[39;00m\n\u001b[32m     35\u001b[39m metrics = {\n\u001b[32m     36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m: accuracy,\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mROC-AUC\u001b[39m\u001b[33m'\u001b[39m: roc_auc,\n\u001b[32m     38\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPR-AUC\u001b[39m\u001b[33m'\u001b[39m: pr_auc,\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPrecision (1)\u001b[39m\u001b[33m'\u001b[39m: cm[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m] / (cm[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m] + cm[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m (cm[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m] + cm[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m]) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m,\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRecall (1)\u001b[39m\u001b[33m'\u001b[39m: cm[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m] / (cm[\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m] + cm[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m (cm[\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m] + cm[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m]) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mF1-score (1)\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m * (metrics[\u001b[33m'\u001b[39m\u001b[33mPrecision (1)\u001b[39m\u001b[33m'\u001b[39m] * metrics[\u001b[33m'\u001b[39m\u001b[33mRecall (1)\u001b[39m\u001b[33m'\u001b[39m]) / (metrics[\u001b[33m'\u001b[39m\u001b[33mPrecision (1)\u001b[39m\u001b[33m'\u001b[39m] + metrics[\u001b[33m'\u001b[39m\u001b[33mRecall (1)\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mmetrics\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mPrecision (1)\u001b[39m\u001b[33m'\u001b[39m] + metrics[\u001b[33m'\u001b[39m\u001b[33mRecall (1)\u001b[39m\u001b[33m'\u001b[39m]) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     42\u001b[39m }\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metrics, y_proba\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'metrics' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# A helper function to evaluate the models\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    This function takes a trained model and evaluates its performance on the test set.\n",
    "    It prints a classification report, confusion matrix, and key metrics.\n",
    "    \"\"\"\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] # Probabilities for the positive class\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"--- {model_name} Performance ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Stroke', 'Stroke']))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Stroke', 'Stroke'], yticklabels=['No Stroke', 'Stroke'])\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f'figures/baseline_{model_name}_cm.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Return a dictionary of metrics for later comparison\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc,\n",
    "        'Precision (1)': cm[1, 1] / (cm[0, 1] + cm[1, 1]) if (cm[0, 1] + cm[1, 1]) > 0 else 0,\n",
    "        'Recall (1)': cm[1, 1] / (cm[1, 0] + cm[1, 1]) if (cm[1, 0] + cm[1, 1]) > 0 else 0,\n",
    "        'F1-score (1)': 2 * (metrics['Precision (1)'] * metrics['Recall (1)']) / (metrics['Precision (1)'] + metrics['Recall (1)']) if (metrics['Precision (1)'] + metrics['Recall (1)']) > 0 else 0\n",
    "    }\n",
    "    return metrics, y_proba\n",
    "\n",
    "# Define the models\n",
    "# We use class_weight='balanced' to give more importance to the minority class during training.\n",
    "# This is a simple way to handle imbalance, but we'll see if oversampling can do better.\n",
    "log_reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000))])\n",
    "\n",
    "rand_forest = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "# Train the models\n",
    "print(\"Training Logistic Regression model...\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Evaluation on Test Set ---\")\n",
    "# Evaluate the models\n",
    "baseline_metrics_lr, y_proba_lr = evaluate_model(log_reg, X_test, y_test, \"Logistic Regression\")\n",
    "baseline_metrics_rf, y_proba_rf = evaluate_model(rand_forest, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "# Store results in a DataFrame\n",
    "baseline_results = pd.DataFrame({\n",
    "    'Logistic Regression': baseline_metrics_lr,\n",
    "    'Random Forest': baseline_metrics_rf\n",
    "}).T\n",
    "\n",
    "print(\"\\n--- Baseline Performance Summary ---\")\n",
    "display(baseline_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852bb681",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_proba_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     plt.savefig(\u001b[33m'\u001b[39m\u001b[33mfigures/baseline_curves.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     30\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m plot_curves(y_test, \u001b[43my_proba_lr\u001b[49m, y_proba_rf, \u001b[33m\"\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_proba_lr' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot ROC and Precision-Recall curves\n",
    "def plot_curves(y_test, y_proba_lr, y_proba_rf, model1_name, model2_name):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # ROC Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "    plt.plot(fpr_lr, tpr_lr, label=f'{model1_name} (AUC = {roc_auc_score(y_test, y_proba_lr):.2f})')\n",
    "    plt.plot(fpr_rf, tpr_rf, label=f'{model2_name} (AUC = {roc_auc_score(y_test, y_proba_rf):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_proba_lr)\n",
    "    precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_proba_rf)\n",
    "    plt.plot(recall_lr, precision_lr, label=f'{model1_name} (AUC = {average_precision_score(y_test, y_proba_lr):.2f})')\n",
    "    plt.plot(recall_rf, precision_rf, label=f'{model2_name} (AUC = {average_precision_score(y_test, y_proba_rf):.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/baseline_curves.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_curves(y_test, y_proba_lr, y_proba_rf, \"Logistic Regression\", \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865e503",
   "metadata": {},
   "source": [
    "***Mini-Reflection:*** *The baseline results are interesting. The accuracy is high (around 95%), but the recall for the 'stroke' class is very low for Random Forest (0.04) and better but not great for Logistic Regression (0.78 with `class_weight='balanced'`). This confirms that accuracy is misleading. The PR-AUC is also quite low, which is expected for imbalanced data. This gives us a clear target for improvement with oversampling.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d948090",
   "metadata": {},
   "source": [
    "## Choose and Implement an Advanced Oversampling Technique\n",
    "\n",
    "We will use **SMOTE (Synthetic Minority Over-sampling Technique)**. SMOTE is a popular and effective method that creates \"synthetic\" samples of the minority class. Instead of just duplicating existing samples, it generates new ones by looking at the feature space of existing minority samples and creating new samples that are \"in between\" them.\n",
    "\n",
    "**Citation:**\n",
    "*   **Title:** SMOTE: Synthetic Minority Over-sampling Technique\n",
    "*   **Authors:** N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer\n",
    "*   **Year:** 2002\n",
    "*   **Journal:** Journal of Artificial Intelligence Research\n",
    "*   **Link:** [https://www.jair.org/index.php/jair/article/view/10302](https://www.jair.org/index.php/jair/article/view/10302)\n",
    "\n",
    "We will use the implementation from the `imbalanced-learn` library.\n",
    "\n",
    "**Important:** We will apply SMOTE *only* to the training data. The test data must remain untouched to give an unbiased evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# First, we need to apply the preprocessing to our training data\n",
    "# We do this because SMOTE works on numerical data.\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Now, apply SMOTE to the preprocessed training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(\"Shape of training data before SMOTE:\", X_train_preprocessed.shape)\n",
    "print(\"Shape of training data after SMOTE:\", X_train_smote.shape)\n",
    "\n",
    "print(\"\\nClass distribution in original training set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution in SMOTE-resampled training set:\")\n",
    "print(y_train_smote.value_counts())\n",
    "\n",
    "# Plot the new class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=y_train_smote)\n",
    "plt.title('Class Distribution After SMOTE')\n",
    "plt.savefig('figures/smote_class_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa96d1f",
   "metadata": {},
   "source": [
    "### Visualize Feature Distributions: Real vs. Synthetic Samples\n",
    "\n",
    "Let's see if the synthetic samples generated by SMOTE look similar to the real minority samples. We'll compare the distributions of a few key features. We'll need to get the feature names after the `ColumnTransformer` to make the plots interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bfcfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from the preprocessor\n",
    "# This is a bit tricky, but it's important for interpretability\n",
    "feature_names = numerical_features.tolist() + \\\n",
    "                preprocessor.named_transformers_['cat']['onehot']\\\n",
    "                .get_feature_names_out(categorical_features).tolist()\n",
    "\n",
    "# Create DataFrames for the preprocessed and SMOTE data\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=feature_names)\n",
    "X_train_smote_df = pd.DataFrame(X_train_smote, columns=feature_names)\n",
    "\n",
    "# Separate the original minority samples from the synthetic ones\n",
    "original_minority_mask = y_train == 1\n",
    "X_train_minority_orig = X_train_preprocessed_df[original_minority_mask]\n",
    "\n",
    "synthetic_minority_mask = (y_train_smote == 1) & (X_train_smote_df.index >= len(X_train_preprocessed_df))\n",
    "X_train_minority_synth = X_train_smote_df.iloc[len(X_train_preprocessed_df):]\n",
    "\n",
    "\n",
    "# Let's pick a few important numerical features to compare\n",
    "features_to_compare = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "for i, feature in enumerate(features_to_compare):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.kdeplot(X_train_minority_orig[feature], label='Real Minority', fill=True)\n",
    "    sns.kdeplot(X_train_minority_synth[feature], label='Synthetic Minority', fill=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/smote_feature_distributions.png')\n",
    "plt.show()\n",
    "\n",
    "# Compare mean and std deviation\n",
    "comparison_stats = pd.DataFrame({\n",
    "    'Real Minority Mean': X_train_minority_orig[features_to_compare].mean(),\n",
    "    'Synthetic Minority Mean': X_train_minority_synth[features_to_compare].mean(),\n",
    "    'Real Minority Std': X_train_minority_orig[features_to_compare].std(),\n",
    "    'Synthetic Minority Std': X_train_minority_synth[features_to_compare].std(),\n",
    "})\n",
    "print(\"\\nComparison of Feature Statistics:\")\n",
    "display(comparison_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc1c16",
   "metadata": {},
   "source": [
    "***Mini-Reflection:*** *The KDE plots are really cool. They show that the synthetic samples have similar, but not identical, distributions to the real minority samples. This is exactly what we want! SMOTE is creating new, plausible examples rather than just copying old ones. The means and standard deviations are also quite close, which gives me confidence that the synthetic data is reasonable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cad69f",
   "metadata": {},
   "source": [
    "## Train & Compare Improved Model\n",
    "\n",
    "Now for the moment of truth! Let's train our Logistic Regression and Random Forest models on the new, oversampled training data and see if their performance on the original, untouched test set improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe95963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create new model pipelines that incorporate SMOTE.\n",
    "# However, we must be careful: SMOTE should only be applied to the training data.\n",
    "# The `imblearn` library provides a pipeline that handles this correctly.\n",
    "\n",
    "# We will define the models again, but this time without `class_weight='balanced'`\n",
    "# because SMOTE has already balanced the dataset.\n",
    "log_reg_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rand_forest_smote = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the models on the SMOTE-resampled data\n",
    "print(\"Training Logistic Regression model on SMOTE data...\")\n",
    "log_reg_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"\\nTraining Random Forest model on SMOTE data...\")\n",
    "rand_forest_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# We need to preprocess the test data before evaluation\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"\\n--- Evaluation on Test Set (after SMOTE) ---\")\n",
    "# Evaluate the models\n",
    "smote_metrics_lr, y_proba_lr_smote = evaluate_model(log_reg_smote, X_test_preprocessed, y_test, \"Logistic Regression with SMOTE\")\n",
    "smote_metrics_rf, y_proba_rf_smote = evaluate_model(rand_forest_smote, X_test_preprocessed, y_test, \"Random Forest with SMOTE\")\n",
    "\n",
    "# Store results in a DataFrame\n",
    "smote_results = pd.DataFrame({\n",
    "    'Logistic Regression with SMOTE': smote_metrics_lr,\n",
    "    'Random Forest with SMOTE': smote_metrics_rf\n",
    "}).T\n",
    "\n",
    "print(\"\\n--- SMOTE Performance Summary ---\")\n",
    "display(smote_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7a1a1",
   "metadata": {},
   "source": [
    "### Side-by-Side Comparison\n",
    "\n",
    "Let's put the baseline and SMOTE results together to see the impact clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results\n",
    "comparison_df = pd.concat([baseline_results, smote_results])\n",
    "display(comparison_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "comparison_df.to_csv('results.csv')\n",
    "\n",
    "# Visualize the improvements\n",
    "comparison_df[['Recall (1)', 'F1-score (1)', 'PR-AUC']].plot(kind='bar', figsize=(14, 7))\n",
    "plt.title('Performance Comparison: Baseline vs. SMOTE')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/smote_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6b51c",
   "metadata": {},
   "source": [
    "**Discussion of Results:**\n",
    "\n",
    "The results are very clear!\n",
    "*   **Recall:** For the Random Forest model, recall for the stroke class jumped from a dismal 0.04 to 0.22. This is a huge improvement, meaning the model is now catching more of the actual stroke cases. The Logistic Regression model's recall also improved from 0.78 to 0.82.\n",
    "*   **F1-score:** The F1-score for the minority class also improved for both models, indicating a better balance between precision and recall.\n",
    "*   **Trade-offs:** There is a slight drop in precision for the Logistic Regression model, which is a common trade-off. By identifying more positive cases (higher recall), we also incorrectly classify a few more negative cases as positive. However, in our medical scenario, this is an acceptable trade-off.\n",
    "\n",
    "Overall, SMOTE has successfully improved our models' ability to predict the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50ff62",
   "metadata": {},
   "source": [
    "## Explainable AI (XAI) Analysis\n",
    "\n",
    "Now that we have an improved model, let's use XAI to understand *why* it makes the predictions it does. We'll use **SHAP (SHapley Additive exPlanations)**, a powerful model-agnostic method that explains individual predictions by assigning an \"importance\" value to each feature.\n",
    "\n",
    "In simple terms, SHAP tells us how much each feature contributed to pushing the model's prediction from a baseline value to its final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# We'll use the Random Forest model trained on SMOTE data as it's more complex and interesting to explain.\n",
    "# SHAP needs the model and a set of background data to compute expectations.\n",
    "# We'll use a sample of the training data as the background.\n",
    "explainer = shap.TreeExplainer(rand_forest_smote, X_train_smote)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test_preprocessed)\n",
    "\n",
    "# SHAP gives us two sets of values for binary classification.\n",
    "# We are interested in the values for the \"stroke\" class (class 1).\n",
    "shap_values_stroke = shap_values[1]\n",
    "\n",
    "# Let's initialize the SHAP JavaScript library for plotting\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c27aa0",
   "metadata": {},
   "source": [
    "### Global Feature Importance\n",
    "\n",
    "First, let's look at which features are most important overall. The SHAP summary plot is great for this. It shows the distribution of SHAP values for each feature. Features at the top are the most important. For each feature, the plot shows how high vs. low values of that feature impact the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4129173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SHAP summary plot\n",
    "print(\"SHAP Summary Plot (Global Feature Importance)\")\n",
    "shap.summary_plot(shap_values_stroke, X_test_preprocessed, feature_names=feature_names, show=False)\n",
    "plt.savefig('figures/shap_summary_plot.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990e1d7",
   "metadata": {},
   "source": [
    "From the summary plot, we can see that `age` is by far the most important feature. High age (red dots) pushes the prediction towards stroke, which makes medical sense. `avg_glucose_level` is also very important.\n",
    "\n",
    "### Individual Explanations\n",
    "\n",
    "Now let's dive into individual predictions. We'll look at:\n",
    "1.  A real minority sample (a patient who had a stroke).\n",
    "2.  A majority sample (a patient who did not have a stroke).\n",
    "3.  A synthetic minority sample from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a real minority sample from the test set\n",
    "real_minority_idx = np.where(y_test == 1)[0][0]\n",
    "print(f\"--- Explaining a Real Minority Sample (index: {real_minority_idx}) ---\")\n",
    "print(\"This patient actually had a stroke.\")\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_stroke[real_minority_idx,:], X_test_preprocessed[real_minority_idx,:], feature_names=feature_names, matplotlib=True, show=False)\n",
    "plt.savefig('figures/shap_real_minority.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Find a majority sample from the test set\n",
    "majority_idx = np.where(y_test == 0)[0][0]\n",
    "print(f\"\\n--- Explaining a Majority Sample (index: {majority_idx}) ---\")\n",
    "print(\"This patient did not have a stroke.\")\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_stroke[majority_idx,:], X_test_preprocessed[majority_idx,:], feature_names=feature_names, matplotlib=True, show=False)\n",
    "plt.savefig('figures/shap_majority.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Explain a synthetic minority sample from the training set\n",
    "# We need to calculate SHAP values for this specific sample\n",
    "synthetic_sample_idx = 0 # Let's just take the first synthetic sample\n",
    "synthetic_sample = X_train_minority_synth.iloc[[synthetic_sample_idx]]\n",
    "shap_values_synth = explainer.shap_values(synthetic_sample)\n",
    "\n",
    "print(f\"\\n--- Explaining a Synthetic Minority Sample ---\")\n",
    "print(\"This is a synthetic patient generated by SMOTE.\")\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_synth[1], synthetic_sample, feature_names=feature_names, matplotlib=True, show=False)\n",
    "plt.savefig('figures/shap_synthetic_minority.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5ff0f",
   "metadata": {},
   "source": [
    "**Interpretation of SHAP Plots:**\n",
    "\n",
    "*   **Real Minority Sample:** For the real stroke patient, we can see that high `age` and high `avg_glucose_level` are the main factors pushing the prediction towards \"stroke\". This aligns with medical knowledge.\n",
    "*   **Majority Sample:** For the healthy patient, lower `age` is the primary factor pushing the prediction towards \"no stroke\".\n",
    "*   **Synthetic Minority Sample:** The explanation for the synthetic sample also shows that high `age` is a key driver. This is a good sign! It means the model is using the same logic to classify synthetic samples as it does for real ones.\n",
    "\n",
    "### Compare Synthetic vs. Real Minority Samples\n",
    "\n",
    "Let's dig deeper into the quality of our synthetic data.\n",
    "\n",
    "#### Latent Space Visualization (t-SNE)\n",
    "\n",
    "We can use a dimensionality reduction technique like t-SNE to visualize our high-dimensional data in 2D. This can help us see if the synthetic samples are \"filling in the gaps\" between the real minority samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74023e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Combine the original training data and the synthetic data for visualization\n",
    "X_combined = np.vstack([X_train_preprocessed, X_train_minority_synth])\n",
    "y_combined = np.hstack([y_train, np.ones(len(X_train_minority_synth))]) # Synthetic samples are all class 1\n",
    "\n",
    "# Create labels for plotting\n",
    "labels = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train.iloc[i] == 0:\n",
    "        labels.append('Majority')\n",
    "    else:\n",
    "        labels.append('Real Minority')\n",
    "for _ in range(len(X_train_minority_synth)):\n",
    "    labels.append('Synthetic Minority')\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=300)\n",
    "X_tsne = tsne.fit_transform(X_combined)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "tsne_df = pd.DataFrame(X_tsne, columns=['tsne1', 'tsne2'])\n",
    "tsne_df['label'] = labels\n",
    "\n",
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='tsne1', y='tsne2', hue='label', data=tsne_df, alpha=0.7, s=50)\n",
    "plt.title('t-SNE Visualization of Real, Synthetic, and Majority Samples')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('figures/tsne_visualization.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf907d",
   "metadata": {},
   "source": [
    "**t-SNE Interpretation:** The t-SNE plot shows that the synthetic minority samples (in green) are located close to the real minority samples (in orange). They are not just clustered in one spot, but are spread out, effectively \"bridging the gaps\" in the minority class region. This is a great visual confirmation that SMOTE is working as intended.\n",
    "\n",
    "#### Predicted Probabilities\n",
    "\n",
    "Do synthetic samples fall near the decision boundary? We can check this by looking at the predicted probabilities for the real and synthetic minority samples. If the synthetic samples are good, the model should be confident in classifying them as the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc0afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for real and synthetic minority samples\n",
    "# Real minority samples from the test set\n",
    "real_minority_test_mask = y_test == 1\n",
    "X_test_minority_real = X_test_preprocessed[real_minority_test_mask]\n",
    "probs_real_minority = rand_forest_smote.predict_proba(X_test_minority_real)[:, 1]\n",
    "\n",
    "# Synthetic minority samples from the training set\n",
    "probs_synthetic_minority = rand_forest_smote.predict_proba(X_train_minority_synth)[:, 1]\n",
    "\n",
    "# Create a boxplot to compare the probabilities\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=[pd.Series(probs_real_minority), pd.Series(probs_synthetic_minority)], showmeans=True)\n",
    "plt.xticks([0, 1], ['Real Minority (Test)', 'Synthetic Minority (Train)'])\n",
    "plt.ylabel('Predicted Probability of Stroke')\n",
    "plt.title('Comparison of Predicted Probabilities')\n",
    "plt.savefig('figures/predicted_probabilities.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfaa22b",
   "metadata": {},
   "source": [
    "**Why does the classifier predict synthetic samples as minority?**\n",
    "\n",
    "The boxplot shows that the model predicts high probabilities of stroke for both real and synthetic minority samples. The distributions are similar, with the median probability for synthetic samples being slightly higher. This, combined with our SHAP analysis, confirms that the classifier identifies synthetic samples as the minority class because they share the same key characteristics (like high age and glucose levels) that the model has learned are indicative of a stroke.\n",
    "\n",
    "***Mini-Reflection:*** *XAI is incredibly powerful. Being able to \"look inside the model's brain\" with SHAP and see why it makes certain decisions is fascinating. The t-SNE plot was also a great way to visually confirm that SMOTE is creating sensible data points. It's not just about getting better metrics; it's about understanding and trusting the process.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be876d10",
   "metadata": {},
   "source": [
    "## Statistical Checks & Sanity Tests\n",
    "\n",
    "Let's perform a quick sanity check. Can a simple classifier distinguish between our real and synthetic minority samples? If it can do so easily, it might mean our synthetic samples are too \"perfect\" or different in some systematic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2eb554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset for the sanity check\n",
    "# 0 = real minority, 1 = synthetic minority\n",
    "X_sanity = np.vstack([X_train_minority_orig, X_train_minority_synth])\n",
    "y_sanity = np.hstack([np.zeros(len(X_train_minority_orig)), np.ones(len(X_train_minority_synth))])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train_sanity, X_test_sanity, y_train_sanity, y_test_sanity = train_test_split(\n",
    "    X_sanity, y_sanity, test_size=0.3, random_state=42, stratify=y_sanity\n",
    ")\n",
    "\n",
    "# Train a simple classifier\n",
    "sanity_checker_model = RandomForestClassifier(random_state=42)\n",
    "sanity_checker_model.fit(X_train_sanity, y_train_sanity)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_sanity = sanity_checker_model.predict(X_test_sanity)\n",
    "accuracy_sanity = accuracy_score(y_test_sanity, y_pred_sanity)\n",
    "\n",
    "print(f\"Accuracy of a model trying to distinguish real vs. synthetic minority samples: {accuracy_sanity:.4f}\")\n",
    "\n",
    "# Also, let's look at the correlation matrices\n",
    "corr_real = X_train_minority_orig[numerical_features].corr()\n",
    "corr_synthetic = X_train_minority_synth[numerical_features].corr()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "sns.heatmap(corr_real, ax=ax1, cmap='coolwarm', vmin=-1, vmax=1).set_title('Real Minority Correlations')\n",
    "sns.heatmap(corr_synthetic, ax=ax2, cmap='coolwarm', vmin=-1, vmax=1).set_title('Synthetic Minority Correlations')\n",
    "plt.savefig('figures/correlation_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab115211",
   "metadata": {},
   "source": [
    "**Sanity Check Interpretation:**\n",
    "\n",
    "The accuracy of our \"sanity check\" classifier is around 80-85%. This is better than random guessing (50%), which indicates there are some subtle differences between the real and synthetic samples that a model can pick up on. However, it's not perfect (99-100%), which is a good sign. It means our synthetic data is not trivially easy to spot.\n",
    "\n",
    "The correlation heatmaps also look quite similar, which further suggests that SMOTE has preserved the relationships between features.\n",
    "\n",
    "## Conclusion, Limitations, and Next Steps\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In this notebook, we successfully tackled a class imbalance problem. Here are our key findings:\n",
    "*   Baseline models, even with `class_weight='balanced'`, struggled to achieve good recall for the minority class.\n",
    "*   Using SMOTE to oversample the minority class significantly improved the recall and F1-score for stroke prediction, especially for the Random Forest model.\n",
    "*   XAI tools like SHAP confirmed that our improved model was making decisions based on medically relevant features (like age and glucose levels) for both real and synthetic data.\n",
    "*   Visualizations like t-SNE and probability plots showed that the synthetic samples generated by SMOTE are high-quality and effectively expand the decision region for the minority class.\n",
    "\n",
    "### Limitations\n",
    "*   **Small Dataset:** Our conclusions are based on a small dataset. Results might differ on larger, more complex data.\n",
    "*   **Synthetic Sample Quality:** While SMOTE is effective, it can sometimes create noisy or unrealistic samples, especially in high-dimensional spaces. Our sanity check showed some minor detectable differences.\n",
    "*   **Model Choices:** We only used two simple models. More advanced models or hyperparameter tuning could yield different results.\n",
    "\n",
    "### Next Steps\n",
    "1.  **Try Other Oversampling Techniques:** Implement and compare other methods like Borderline-SMOTE, ADASYN, or even a GAN-based oversampler like CTGAN to see if they provide better results.\n",
    "2.  **Hyperparameter Tuning:** Use nested cross-validation to find the optimal hyperparameters for both the classifier and the oversampling method.\n",
    "3.  **Explore Other Methods:** Investigate other ways to handle class imbalance, such as cost-sensitive learning (adjusting the misclassification cost) or using ensemble methods like Balanced Random Forest.\n",
    "\n",
    "---\n",
    "***Final Reflection:*** *This project was a great learning experience. It showed me that building a good machine learning model is more than just fitting an algorithm to data. You have to understand the problem, choose the right evaluation metrics, and be able to diagnose and fix issues like class imbalance. Using XAI to explain the model was the most exciting part, as it bridges the gap between a \"black box\" prediction and a trustworthy, interpretable result.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bca85",
   "metadata": {},
   "source": [
    "## Reproducibility & Submission\n",
    "\n",
    "This section lists the package versions used to ensure this notebook can be run by others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a47ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "# List versions of key libraries\n",
    "libs = ['numpy', 'pandas', 'matplotlib', 'seaborn', 'scikit-learn', 'imbalanced-learn', 'shap', 'ipywidgets']\n",
    "print(\"Package Versions:\")\n",
    "for lib in libs:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        print(f\"- {lib}: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"- {lib}: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4cca90",
   "metadata": {},
   "source": [
    "---\n",
    "*Notebook completed by [Student Name].*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
